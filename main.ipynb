{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f04d7e3",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d37d16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71b19b",
   "metadata": {},
   "source": [
    "# CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3f27f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = \"garbage-dataset\"            # folder sekarang\n",
    "OUT_DIR = \"garbage-dataset-split\"      # folder hasil split\n",
    "VAL_RATIO = 0.2                        # 80/20 split\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LR = 1e-3\n",
    "PATIENCE = 5\n",
    "FREEZE_BACKBONE = False\n",
    "OUTPUT_MODEL_DIR = \"outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeff538",
   "metadata": {},
   "source": [
    "# HELPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "522c225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ef3bf",
   "metadata": {},
   "source": [
    "# 1. SPLIT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2833d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(raw_dir, out_dir, val_ratio=0.2):\n",
    "    raw_dir = Path(raw_dir)\n",
    "    out_dir = Path(out_dir)\n",
    "    train_dir = out_dir / \"train\"\n",
    "    val_dir = out_dir / \"val\"\n",
    "\n",
    "    train_dir.mkdir(parents=True, exist_ok=True)\n",
    "    val_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"üîÑ Splitting dataset...\")\n",
    "\n",
    "    for cls in sorted(os.listdir(raw_dir)):\n",
    "        class_path = raw_dir / cls\n",
    "        if not class_path.is_dir():\n",
    "            continue\n",
    "\n",
    "        imgs = [p for p in class_path.iterdir() if p.is_file()]\n",
    "        random.shuffle(imgs)\n",
    "\n",
    "        split_idx = int(len(imgs) * (1 - val_ratio))\n",
    "        train_imgs = imgs[:split_idx]\n",
    "        val_imgs = imgs[split_idx:]\n",
    "\n",
    "        (train_dir / cls).mkdir(parents=True, exist_ok=True)\n",
    "        (val_dir / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for p in train_imgs:\n",
    "            shutil.copy(p, train_dir / cls / p.name)\n",
    "\n",
    "        for p in val_imgs:\n",
    "            shutil.copy(p, val_dir / cls / p.name)\n",
    "\n",
    "        print(f\"[{cls}] Train: {len(train_imgs)}, Val: {len(val_imgs)}\")\n",
    "\n",
    "    print(\"Split selesai\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c26f33",
   "metadata": {},
   "source": [
    "# 2. Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0167235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(data_dir):\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMG_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(12),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize(int(IMG_SIZE * 1.1)),\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(Path(data_dir) / \"train\", train_tf)\n",
    "    val_dataset = datasets.ImageFolder(Path(data_dir) / \"val\", val_tf)\n",
    "\n",
    "    loaders = {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True),\n",
    "        \"val\": DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False),\n",
    "    }\n",
    "\n",
    "    return loaders, train_dataset.classes, {\"train\": len(train_dataset), \"val\": len(val_dataset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f712c8",
   "metadata": {},
   "source": [
    "# 3. MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65662550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    if FREEZE_BACKBONE:\n",
    "        for name, p in model.named_parameters():\n",
    "            if \"fc\" not in name:\n",
    "                p.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e14f4",
   "metadata": {},
   "source": [
    "# 4. TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61ea73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, sizes, device):\n",
    "    os.makedirs(OUTPUT_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_wts = copy.deepcopy(model.state_dict())\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            model.train() if phase == \"train\" else model.eval()\n",
    "\n",
    "            total_loss = 0\n",
    "            total_correct = 0\n",
    "\n",
    "            loop = tqdm(dataloaders[phase], desc=phase)\n",
    "            for x, y in loop:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    out = model(x)\n",
    "                    _, preds = torch.max(out, 1)\n",
    "                    loss = criterion(out, y)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                total_correct += torch.sum(preds == y).item()\n",
    "\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = total_loss / sizes[phase]\n",
    "            epoch_acc = total_correct / sizes[phase]\n",
    "\n",
    "            print(f\"  {phase} ‚Üí Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == \"val\":\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_wts = copy.deepcopy(model.state_dict())\n",
    "                    torch.save(model.state_dict(), f\"{OUTPUT_MODEL_DIR}/best_model.pth\")\n",
    "                    print(\"  ‚úî Model improved ‚Üí saved\")\n",
    "                    no_improve = 0\n",
    "                else:\n",
    "                    no_improve += 1\n",
    "\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(\"‚èπ Early stopping\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa3a19d",
   "metadata": {},
   "source": [
    "# 5. EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af0f9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, class_names, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            _, p = torch.max(out, 1)\n",
    "\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            labels.extend(y.numpy())\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(labels, preds, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e61b0",
   "metadata": {},
   "source": [
    "# RUN PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3293e283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['battery', 'biological', 'cardboard', 'clothes', 'glass', 'metal', 'paper', 'plastic', 'shoes', 'trash']\n",
      "Sizes: {'train': 15806, 'val': 3956}\n",
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   4%|‚ñç         | 19/494 [02:06<52:37,  6.65s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(\u001b[38;5;28mlen\u001b[39m(class_names))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[0;32m     24\u001b[0m evaluate(model, loaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m], class_names, device)\n",
      "Cell \u001b[1;32mIn[25], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, sizes, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out, y)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 32\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     35\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Miniconda\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Miniconda\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Miniconda\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# Split (hanya jika folder belum ada)\n",
    "if not Path(OUT_DIR).exists():\n",
    "    split_dataset(RAW_DIR, OUT_DIR)\n",
    "\n",
    "# Loaders\n",
    "loaders, class_names, sizes = create_dataloaders(OUT_DIR)\n",
    "\n",
    "with open(\"class_names.json\", \"w\") as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Sizes:\", sizes)\n",
    "\n",
    "# Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = build_model(len(class_names)).to(device)\n",
    "\n",
    "# Training\n",
    "model = train_model(model, loaders, sizes, device)\n",
    "\n",
    "# Evaluation\n",
    "evaluate(model, loaders[\"val\"], class_names, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
